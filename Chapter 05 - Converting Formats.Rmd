---
title: 'R Text Mining: Chapter 5'
author: "Brandon Foltz"
date: "2023-04-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tm)
library(tidytext)
```
```{r}
library(tm)

data("AssociatedPress", package = "topicmodels")
AssociatedPress
```
```{r}
terms <- Terms(AssociatedPress)
head(terms)
```
```{r}
ap_td <- tidy(AssociatedPress)
ap_td
```
```{r}
ap_sentiments <- ap_td|>
  inner_join(get_sentiments("bing"), by = c(term = "word"))

ap_sentiments
```
```{r}
ap_sentiments|>
  count(sentiment, term, wt = count)|>
  ungroup()|>
  filter(n >= 200)|>
  mutate(n = ifelse(sentiment == "negative", -n, n))|>
  mutate(term = reorder(term, n))|>
  ggplot(aes(n, term, fill = sentiment)) +
  geom_col() +
  labs(x = "Contribution to sentiment", y = NULL)
```
```{r}
library(quanteda)
data("data_corpus_inaugural", package = "quanteda")
inaug_dfm <- data_corpus_inaugural|>
  quanteda::tokens()|>
  quanteda::dfm(verbose = FALSE)
inaug_dfm
```
```{r}
inaug_td <- tidy(inaug_dfm)
inaug_td
```
```{r}
inaug_tf_idf <- inaug_td|>
  bind_tf_idf(term, document, count)|>
  arrange(desc(tf_idf))

inaug_tf_idf
```
```{r}
library(tidyr)

year_term_counts <- inaug_td|>
  extract(document, "year", "(\\d+)", convert = TRUE)|>
  complete(year, term, fill = list(count = 0))|>
  group_by(year)|>
  mutate(year_total = sum(count))
```
```{r}
year_term_counts|>
  filter(term %in% c("god", "america", "foreign", "union", "constitution", "freedom"))|>
  ggplot(aes(year, count / year_total)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~ term, scales = "free_y") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(y = "% frequency of work in inaugural address")
```
```{r}
ap_td|>
  cast_dtm(document, term, count)
```
```{r}
ap_td|>
  cast_dfm(document, term, count)
```
```{r}
library(Matrix)

m <- ap_td|>
  cast_sparse(document, term, count)

class(m)
dim(m)
```
```{r}
library(janeaustenr)

austen_dtm <- austen_books()|>
  unnest_tokens(word, text)|>
  count(book, word)|>
  cast_dtm(book, word, n)

austen_dtm
```
```{r}
data("acq")
acq

acq[[1]]
```
```{r}
acq_td <- tidy(acq)
acq_td
```
```{r}
acq_tokens <- acq_td|>
  select(-places)|>
  unnest_tokens(word, text)|>
  anti_join(stop_words, by = "word")

acq_tokens|>
  count(word, sort = TRUE)

acq_tokens|>
  count(id, word)|>
  bind_tf_idf(word, id, n)|>
  arrange(desc(tf_idf))
```
```{r}
#library(tm.plugin.webmining) plugin removed from CRAN
library(purrr)

company <- c("Microsoft", "Apple", "Google", "Amazon", "Facebook",
             "Twitter", "IBM", "Yahoo", "Netflix")
symbol  <- c("MSFT", "AAPL", "GOOG", "AMZN", "FB", 
             "TWTR", "IBM", "YHOO", "NFLX")

download_articles <- function(symbol) {
  WebCorpus(GoogleFinanceSource(paste0("NASDAQ:", symbol)))
}

stock_articles <- tibble(company = company,
                         symbol = symbol) %>%
  mutate(corpus = map(symbol, download_articles))
```

